{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "This notebook is part of the $\\omega radlib$ documentation: https://docs.wradlib.org.\n",
    "\n",
    "Copyright (c) $\\omega radlib$ developers.\n",
    "Distributed under the MIT License. See LICENSE.txt for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load ODIM_H5 Volume data from German Weather Service\n",
    "\n",
    "In this example, we obtain and read the latest 30 minutes of available volumetric radar data from German Weather Service available at [opendata.dwd.de](https://opendata.dwd.de). Finally we do some plotting.\n",
    "\n",
    "This retrieves 6 timesteps of the 10 sweeps (moments DBZH and VRADH) of the DWD volume scan of a distinct radar. This amounts to 120 data files which are combined into one volumetric Cf/Radial2 like xarray powered structure.\n",
    "\n",
    "Exports to single file Odim_H5 and Cf/Radial2 format are shown at the end of this tutorial.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Note** <br>\n",
    "\n",
    "The following code is based on [xarray](https://docs.xarray.dev) and [xradar](https://docs.openradarscience.org/projects/xradar). It claims multiple data files and presents them in a ``DataTree``.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wradlib as wrl\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import xradar as xd\n",
    "\n",
    "try:\n",
    "    get_ipython().run_line_magic(\"matplotlib inline\")\n",
    "except:\n",
    "    plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "import os\n",
    "import io\n",
    "import glob\n",
    "import shutil\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from html.parser import HTMLParser\n",
    "\n",
    "\n",
    "class DWDHTMLParser(HTMLParser):\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag != \"a\":\n",
    "            return\n",
    "        self.links.append(attrs[0][1])\n",
    "\n",
    "\n",
    "parser = DWDHTMLParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from opendata.dwd.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar = \"ESS\"\n",
    "DBZH = \"sweep_vol_z\"\n",
    "VRADH = \"sweep_vol_v\"\n",
    "\n",
    "import certifi\n",
    "\n",
    "opendata_url1 = f\"https://opendata.dwd.de/weather/radar/sites/{DBZH}/{radar.lower()}/hdf5/filter_polarimetric/\"\n",
    "\n",
    "http = urllib3.PoolManager(cert_reqs=\"CERT_REQUIRED\", ca_certs=certifi.where())\n",
    "response = http.request(\"GET\", opendata_url1).data.decode(\"utf-8\")\n",
    "\n",
    "parser.links = []\n",
    "parser.feed(response)\n",
    "filelist1 = parser.links[1:]\n",
    "\n",
    "filelist1.sort(key=lambda x: x.split(\"-\")[2])\n",
    "filelist1.reverse()\n",
    "\n",
    "opendata_url2 = f\"https://opendata.dwd.de/weather/radar/sites/{VRADH}/{radar.lower()}/hdf5/filter_polarimetric/\"\n",
    "\n",
    "http = urllib3.PoolManager(cert_reqs=\"CERT_REQUIRED\", ca_certs=certifi.where())\n",
    "response = http.request(\"GET\", opendata_url2).data.decode(\"utf-8\")\n",
    "\n",
    "parser.links = []\n",
    "parser.feed(response)\n",
    "filelist2 = parser.links[1:]\n",
    "\n",
    "filelist2.sort(key=lambda x: x.split(\"-\")[2])\n",
    "filelist2.reverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up local folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = glob.glob(\"ras07*\")\n",
    "for f in flist:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download latest 24 volumes to current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in filelist1[: 10 * 24]:\n",
    "    with http.request(\n",
    "        \"GET\", os.path.join(opendata_url1, f), preload_content=False\n",
    "    ) as r, open(f, \"wb\") as out:\n",
    "        shutil.copyfileobj(r, out)\n",
    "\n",
    "for f in filelist2[: 10 * 24]:\n",
    "    with http.request(\n",
    "        \"GET\", os.path.join(opendata_url2, f), preload_content=False\n",
    "    ) as r, open(f, \"wb\") as out:\n",
    "        shutil.copyfileobj(r, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_reflectivity = glob.glob(\"ras07*_dbzh_*\")\n",
    "volume_velocity = glob.glob(\"ras07*_vradh_*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_reflectivity = np.array(\n",
    "    sorted(volume_reflectivity, key=lambda x: x.split(\"-\")[2])\n",
    ")\n",
    "volume_velocity = np.array(sorted(volume_velocity, key=lambda x: x.split(\"-\")[2]))\n",
    "volume_reflectivity[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_reflectivity = volume_reflectivity.reshape(-1, 10).T\n",
    "volume_velocity = volume_velocity.reshape(-1, 10).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_reflectivity = sorted(\n",
    "    volume_reflectivity, key=lambda x: x[0].split(\"-\")[1].split(\"_\")[-1]\n",
    ")\n",
    "volume_reflectivity = volume_reflectivity[5:] + volume_reflectivity[:5]\n",
    "volume_velocity = sorted(\n",
    "    volume_velocity, key=lambda x: x[0].split(\"-\")[1].split(\"_\")[-1]\n",
    ")\n",
    "volume_velocity = volume_velocity[5:] + volume_velocity[:5]\n",
    "len(volume_reflectivity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data into xarray powered structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsl = []\n",
    "reindex_angle = dict(\n",
    "    tolerance=1.0, start_angle=0, stop_angle=360, angle_res=1.0, direction=1\n",
    ")\n",
    "for i, (r, v) in enumerate(zip(volume_reflectivity, volume_velocity)):\n",
    "    ds0 = [\n",
    "        xr.open_dataset(\n",
    "            r0,\n",
    "            engine=\"odim\",\n",
    "            group=\"sweep_0\",\n",
    "            reindex_angle=reindex_angle,\n",
    "            fix_second_angle=True,\n",
    "        )\n",
    "        for r0 in r\n",
    "    ]\n",
    "    ds0 = [r0.assign_coords(sweep_mode=r0.sweep_mode.min()) for r0 in ds0]\n",
    "    ds1 = [\n",
    "        xr.open_dataset(\n",
    "            v0,\n",
    "            engine=\"odim\",\n",
    "            group=\"sweep_0\",\n",
    "            reindex_angle=reindex_angle,\n",
    "            fix_second_angle=True,\n",
    "        )\n",
    "        for v0 in v\n",
    "    ]\n",
    "    ds1 = [r1.assign_coords(sweep_mode=r1.sweep_mode.min()) for r1 in ds1]\n",
    "    ds2 = [\n",
    "        xr.merge([r0, v0], compat=\"no_conflicts\").assign(\n",
    "            volume_time=r0.time.min().dt.floor(\"5min\")\n",
    "        )\n",
    "        for r0, v0 in zip(ds0, ds1)\n",
    "    ]\n",
    "    ds2 = [r2.wrl.georef.georeference() for r2 in ds2]\n",
    "    ds = xr.concat(ds2, \"volume_time\")\n",
    "    dsl.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = {\"/\": xd.io.backends.common._get_required_root_dataset(dsl, optional=False)}\n",
    "for i, swp in enumerate(dsl):\n",
    "    dsl[i][\"sweep_number\"] = i\n",
    "dtree = xd.io.backends.common._attach_sweep_groups(dtree, dsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = xr.DataTree.from_dict(dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect structure\n",
    "### Root Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweep Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol[\"sweep_0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot sweeps\n",
    "### DBZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol[\"sweep_0\"].isel(volume_time=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol.match(\"sweep*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swp = vol[\"sweep_0\"].isel(volume_time=0).ds\n",
    "swp.sweep_fixed_angle.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, gs = plt.subplots(\n",
    "    4, 3, figsize=(20, 30), sharex=True, sharey=True, constrained_layout=True\n",
    ")\n",
    "\n",
    "for i, grp in enumerate(vol.match(\"sweep_*\")):\n",
    "    ax = gs.flat[i]\n",
    "    swp = vol[grp].isel(volume_time=0).ds\n",
    "    swp.DBZH.wrl.vis.plot(ax=ax, fig=fig)\n",
    "    ax.set_title(swp.sweep_fixed_angle.values)\n",
    "\n",
    "fig.delaxes(gs.flat[-2])\n",
    "fig.delaxes(gs.flat[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VRADH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, gs = plt.subplots(\n",
    "    4, 3, figsize=(20, 30), sharex=True, sharey=True, constrained_layout=True\n",
    ")\n",
    "\n",
    "for i, grp in enumerate(vol.match(\"sweep_*\")):\n",
    "    ax = gs.flat[i]\n",
    "    swp = vol[grp].isel(volume_time=0).ds\n",
    "    swp.VRADH.wrl.vis.plot(ax=ax, fig=fig)\n",
    "    ax.set_title(swp.sweep_fixed_angle.values)\n",
    "\n",
    "fig.delaxes(gs.flat[-2])\n",
    "fig.delaxes(gs.flat[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot single sweep using cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol0 = vol.isel(volume_time=0)\n",
    "swp = vol0[\"sweep_9\"].ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "map_trans = ccrs.AzimuthalEquidistant(\n",
    "    central_latitude=swp.latitude.values,\n",
    "    central_longitude=swp.longitude.values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_proj = ccrs.AzimuthalEquidistant(\n",
    "    central_latitude=swp.latitude.values,\n",
    "    central_longitude=swp.longitude.values,\n",
    ")\n",
    "\n",
    "pm = swp.DBZH.wrl.georef.georeference().wrl.vis.plot(crs=map_proj)\n",
    "ax = plt.gca()\n",
    "ax.gridlines(crs=map_proj)\n",
    "print(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_proj = ccrs.Mercator(central_longitude=swp.longitude.values)\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection=map_proj)\n",
    "pm = swp.DBZH.wrl.georef.georeference().wrl.vis.plot(ax=ax)\n",
    "ax.gridlines(draw_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "proj = ccrs.AzimuthalEquidistant(\n",
    "    central_latitude=swp.latitude.values,\n",
    "    central_longitude=swp.longitude.values,\n",
    ")\n",
    "ax = fig.add_subplot(111, projection=proj)\n",
    "pm = swp.DBZH.wrl.georef.georeference().wrl.vis.plot(ax=ax)\n",
    "ax.gridlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect radar moments\n",
    "\n",
    "The DataArrays can be accessed by key or by attribute. Each DataArray inherits dimensions and coordinates of it's parent dataset. There are attributes connected which are defined by Cf/Radial and/or ODIM_H5 standard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol[\"sweep_9\"].isel(volume_time=0).ds.DBZH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol[\"sweep_9\"].isel(volume_time=0).ds.sweep_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Quasi Vertical Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = vol[\"sweep_9\"]\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "ts.ds.DBZH.median(\"azimuth\").plot(x=\"volume_time\", vmin=-10, vmax=30, ax=ax)\n",
    "ax.set_title(f\"{np.datetime_as_string(ts.ds.time[0][0].values, unit='D')}\")\n",
    "ax.set_ylim(0, 20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to OdimH5\n",
    "\n",
    "This exports the radar volume at given timestep including all moments into one ODIM_H5 compliant data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd.io.to_odim(vol0, \"dwd_odim.h5\", source=\"RAD:DWD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Cf/Radial2\n",
    "\n",
    "This exports the radar volume at given timestep including all moments into one Cf/Radial2 compliant data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xd.io.to_cfradial2(vol0, \"dwd_cfradial2.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1 = xd.io.open_odim_datatree(\"dwd_odim.h5\")\n",
    "display(vol1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol2 = xr.open_datatree(\"dwd_cfradial2.nc\")\n",
    "display(vol2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
