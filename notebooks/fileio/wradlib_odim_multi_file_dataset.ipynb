{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of the $\\omega radlib$ documentation: https://docs.wradlib.org.\n",
    "\n",
    "Copyright (c) $\\omega radlib$ developers.\n",
    "Distributed under the MIT License. See LICENSE.txt for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi File OdimH5 reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "**Note** <br>\n",
    "\n",
    "The following functionality is deprecated. Please use the [xarray backend loaders](fileio/wradlib_xarray_backends.ipynb) instead.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation is based on several classes which are described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Overview\n",
    "\n",
    "### XRadBase\n",
    "\n",
    "Implements `collections.abc.MutableSequence` for holding sequential data in the derived classes (eg. sweeps, timeseries, moments).\n",
    "\n",
    "### OdimH5GroupAttributeMixin\n",
    "\n",
    "Implements properties for `XRadMoment`, `XRadSweep`, `XRadTimeSeries` and `XRadVolume` to nicely acquire ODIM group metadata, eg. `how`, `what` and `where` groups. Other wanted attributes can be acquired via `attrs`-property and other (sub-) groups be inspected via `groups`-property.\n",
    "\n",
    "### OdimH5SweepMetaDataMixin\n",
    "\n",
    "Implements properties for `XRadSweep` to nicely acquire ODIM sweep metadata, eg. `a1gate`, `azimuth`, `nrays`, `nbins` etc.\n",
    "\n",
    "### XRadMoment\n",
    "\n",
    "Uses `OdimH5GroupAttributeMixin` to access ODIM metadata. Does not hold any data. Property `data` fetches the moment as xarray DataArray from the parent `XRadSweep`. \n",
    "\n",
    "### XRadSweep\n",
    "\n",
    "Inherits from `XRadBase`, uses `OdimH5GroupAttributeMixin` and `OdimH5SweepMetaDataMixin`. Worker class, where everything happens. Implements methods and properties to retrieve sweep metadata and data. Holds `XRadMoments` in it's `MutableSequence`. Property `data` is used to load and cache the `XRadMoments` as combined xarray Dataset. Implements a whole arsenal of other properties to inspect metadata.\n",
    "\n",
    "#### XRadSweepOdim:\n",
    "\n",
    "Inherits from `XRadSweep`. Accounts for ODIM data layout.\n",
    "\n",
    "#### XRadSweepGamic:\n",
    "\n",
    "Inherits from `XRadSweep`. Accounts for GAMIC data layout.\n",
    "\n",
    "### XRadTimeSeries\n",
    "\n",
    "Inherits from `XRadBase`, holds several `XRadSweep` objects in it's `MutableSequence`. Property `data` is used to concat and cache the `XRadSweeps` as xarray Dataset along time dimension. Implements check methods to quickly get information about layout of timeseries data. \n",
    "\n",
    "### XRadVolume\n",
    "\n",
    "Inherits from `XRadBase`, holds several `XRadTimeSeries` objects in it's `MutableSequence`. Implements CfRadial2 like `root` property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Function\n",
    "\n",
    "For opening ODIMH5 datafiles `wrl.io.open_odim(filename, loader='h5py', **kwargs)` can be used.\n",
    "\n",
    "The user can decide which loader to use (`h5py`, `h5netcdf` or `netcdf4`) to open the files for reading. The output should be the same in any case, although the memory footprint can differ quite substantially. The default loader is `netcdf4` if loader isn't specified.\n",
    "\n",
    "The datasets are retrieved in further succession via `xarray.open_dataset()` in combination with either `xarray.backends.H5NetCDFStore` (for loader `h5py` and `h5netcdf`) or `xarray.backends.NetCDF4DataStore` (for loader `netcdf4`.\n",
    "\n",
    "Possible keyword arguments are:\n",
    "\n",
    "- `mask_and_scale` *bool* - If True, apply mask and scale to moment data arrays\n",
    "- `decode_coords` *bool* - If True, decode ODIMH5 coordinates\n",
    "- `decode_times` *bool* - If True, decode times into datetime objects\n",
    "- `chunks` *int or dict* - Data loaded as dask array\n",
    "- `parallel` *bool* - if True, use `dask.delayed` to load moments in parallel\n",
    "\n",
    "The user is encouraged to play with the keyword arguments for best alignment with the needs in terms of speed and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wradlib as wrl\n",
    "import warnings\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as pl\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import glob\n",
    "\n",
    "try:\n",
    "    get_ipython().run_line_magic(\"matplotlib inline\")\n",
    "except:\n",
    "    pl.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "process = psutil.Process(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_usage_psutil():\n",
    "    # return the memory usage in MB\n",
    "    rocess = psutil.Process(os.getpid())\n",
    "    mem = process.memory_full_info().uss / float(1 << 20)\n",
    "    return mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_memory():\n",
    "    mem0 = memory_usage_psutil()\n",
    "    print(gc.collect())\n",
    "    proc = psutil.Process()\n",
    "    mem1 = memory_usage_psutil()\n",
    "    print(\"Memory freed: {0:.5f} MB\".format((mem0 - mem1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_open_files(full=False):\n",
    "    proc = psutil.Process()\n",
    "    print(len(proc.open_files()))\n",
    "    if full:\n",
    "        print(proc.open_files())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "flist = [\n",
    "    \"hdf5/behel/20200207130000.rad.behel.pvol.dbzh.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207130000.rad.behel.pvol.rhohv.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207130000.rad.behel.pvol.vrad.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207130000.rad.behel.pvol.wrad.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207130500.rad.behel.pvol.dbzh.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207130500.rad.behel.pvol.rhohv.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207130500.rad.behel.pvol.vrad.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207130500.rad.behel.pvol.wrad.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207131000.rad.behel.pvol.dbzh.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207131000.rad.behel.pvol.rhohv.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207131000.rad.behel.pvol.vrad.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207131000.rad.behel.pvol.wrad.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207131500.rad.behel.pvol.dbzh.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207131500.rad.behel.pvol.rhohv.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207131500.rad.behel.pvol.vrad.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207131500.rad.behel.pvol.wrad.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207132000.rad.behel.pvol.dbzh.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207132000.rad.behel.pvol.rhohv.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207132000.rad.behel.pvol.vrad.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207132000.rad.behel.pvol.wrad.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207132500.rad.behel.pvol.dbzh.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207132500.rad.behel.pvol.rhohv.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207132500.rad.behel.pvol.vrad.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207132500.rad.behel.pvol.wrad.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207133000.rad.behel.pvol.dbzh.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207133000.rad.behel.pvol.rhohv.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207133000.rad.behel.pvol.vrad.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207133000.rad.behel.pvol.wrad.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207133500.rad.behel.pvol.dbzh.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207133500.rad.behel.pvol.rhohv.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207133500.rad.behel.pvol.vrad.scanz.hdf\",\n",
    "    \"hdf5/behel/20200207133500.rad.behel.pvol.wrad.scanz.hdf\",\n",
    "]\n",
    "f = [wrl.util.get_wradlib_data_file(f) for f in flist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_start = memory_usage_psutil()\n",
    "print(\"Current Memory:\", mem_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_open_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claim Files into class structure\n",
    "\n",
    "The different files will be opened with `h5netcdf`, `h5py` or `netcdf4` depending on `loader` keyword. Only absolutely neccessary metadata (time, elevation) is read from the files to be used for aligning into the structure.\n",
    "\n",
    "Normally `h5py` is the most performant loader for `ODIM` data. But your mileage may vary.\n",
    "\n",
    "This means that every file is opened once and the filehandle is distributed to `XRadSweep`. If `XRadSweep` will be destroyed, the memory will be ready for garbage collection.\n",
    "\n",
    "Under the hood `netcdf4` or `h5netcdf` will be used to open data as `xarray.Dataset` depending on the loader-type. All filehandling issues are moved to xarray. No memory holes, no need to track filehandles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vol = wrl.io.xarray_depr.open_odim(f, loader=\"h5py\", chunks={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_open_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview type and lenght"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Volume:\", type(vol), len(vol))\n",
    "print(\"TimeSeries:\", type(vol[0]), len(vol[0]))\n",
    "print(\"Sweep:\", type(vol[0][0]), len(vol[0][0]))\n",
    "print(\"Moment:\", type(vol[0][0][0]), vol[0][0][0].quantity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview Contents (__repr__())\n",
    "\n",
    "When printing the objects, they tell us a little about themselves and the data they can get access to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume\n",
    "\n",
    "Here we see, that it is of type `wradlib.XRadVolume`. It holds 12 sweeps with the shown elevations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimeSeries\n",
    "\n",
    "Here we see, that it is of type `wradlib.XRadTimeseries`. It holds 8 timesteps with a data layout of 360 azimuths by 800 range bins. The elevation is 25.0 deg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vol[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweep\n",
    "\n",
    "Here we see, that it is of type `wradlib.XRadSweepOdim`, which means it is leaded from ODIMH5 standard data. It holds data with layout of 360 azimuths by 800 range bins. The elevation is 25.0 deg. It consists of the radar moments `DBZH`, `RHOHV`, `VRAD` and `WRAD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vol[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moment\n",
    "\n",
    "Here we see, that it is of type `wradlib.XRadMoment`. It holds data with layout of 360 azimuths by 800 range bins. The elevation is 25.0 deg. It is the radar moment `DBZH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vol[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing metadata via `OdimH5GroupAttributeMixin`\n",
    "\n",
    "\n",
    "You can access underlying metadata for every object. The properties `ncpath`, `ncid`, `ncfile` and `filename` give information about the location of the metadata. Properties `groups` and `attrs` give information about attached subgroups and attributes. `how`, `what` and `where` return the contents of the respective ODIMH5-subgroups if available.\n",
    "\n",
    "As long as the objects are not deleted the according files are open and the handles can be used to retrieve data from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume\n",
    "\n",
    "The `OdimH5GroupAttributeMixin` access in `XRadVolume` will retrieve the root-metadata of the first file of the first timeseries, which is the first volume file in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"path:\", vol.ncpath)\n",
    "print(\"  id:\", vol.ncid)\n",
    "print(\"file:\", vol.ncfile)\n",
    "print(\"name:\", vol.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vol.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vol.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vol.how)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vol.what)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vol.where)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries\n",
    "\n",
    "The `OdimH5GroupAttributeMixin` access in `XRadTimeseries` will retrieve the group-metadata of the first sweep of the selected timeseries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = vol[0]\n",
    "print(\"path:\", ts.ncpath)\n",
    "print(\"  id:\", ts.ncid)\n",
    "print(\"file:\", ts.ncfile)\n",
    "print(\"name:\", ts.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts.how)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts.what)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts.where)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweep\n",
    "\n",
    "The `OdimH5GroupAttributeMixin` access in `XRadSweep` will retrieve the group-metadata of the selected sweep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swp = vol[0][5]\n",
    "print(\"path:\", swp.ncpath)\n",
    "print(\"  id:\", swp.ncid)\n",
    "print(\"file:\", swp.ncfile)\n",
    "print(\"name:\", swp.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(swp.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(swp.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(swp.how)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(swp.what)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(swp.where)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moment\n",
    "\n",
    "The `OdimH5GroupAttributeMixin` access in `XRadMoment` will retrieve the group-metadata of the selected moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mom = vol[0][0][0]\n",
    "print(\"path:\", mom.ncpath)\n",
    "print(\"  id:\", mom.ncid)\n",
    "print(\"file:\", mom.ncfile)\n",
    "print(\"name:\", mom.filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mom.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mom.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mom.what)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CfRadial2 style root object\n",
    "\n",
    "The XRadVolume object is equipped with a CfRadial2-style `root`-object, where some information can be retrieved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol.root"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get hold of data using xarray\n",
    "\n",
    "- The outer class instance `XRadVolume` does not contain a `.data`-property because the volume cannot be represented using xarray. \n",
    "- `XRadTimeseries` `.data` works on the sweep level, it can contain one or multiple consecutive sweeps.\n",
    "    It will be created on the fly from the `XRadSweep` `.data` xarray.Dataset objects via concatenation.\n",
    "- `XRadSweep` `.data` is one single sweep containing multiple radar moments. It is created **and** cached when first accessed.\n",
    "- `XRadMoment` `.data` is one single moment as xarray DataArray, which is claimed from the parent `XRadSweep`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"First Access\")\n",
    "mem0 = memory_usage_psutil()\n",
    "print(vol[-2][0][0].data)\n",
    "mem1 = memory_usage_psutil()\n",
    "print(\"Memory: {} - {}\".format(mem0, mem1))\n",
    "print(\"Memory added: {0:.5f} MB\".format((mem1 - mem0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Second Access\")\n",
    "mem0 = memory_usage_psutil()\n",
    "print(vol[-2][0][0].data)\n",
    "mem1 = memory_usage_psutil()\n",
    "print(\"Memory: {} - {}\".format(mem0, mem1))\n",
    "print(\"Memory added: {0:.5f} MB\".format((mem1 - mem0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"First Access\")\n",
    "mem0 = memory_usage_psutil()\n",
    "print(vol[-1][0].data)\n",
    "mem1 = memory_usage_psutil()\n",
    "print(\"Memory: {} - {}\".format(mem0, mem1))\n",
    "print(\"Memory added: {0:.5f} MB\".format((mem1 - mem0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Second Access\")\n",
    "mem0 = memory_usage_psutil()\n",
    "print(vol[-1][0].data)\n",
    "mem1 = memory_usage_psutil()\n",
    "print(\"Memory: {} - {}\".format(mem0, mem1))\n",
    "print(\"Memory added: {0:.5f} MB\".format((mem1 - mem0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"First Access\")\n",
    "mem0 = memory_usage_psutil()\n",
    "print(vol[-1].data)\n",
    "mem1 = memory_usage_psutil()\n",
    "print(\"Memory: {} - {}\".format(mem0, mem1))\n",
    "print(\"Memory added: {0:.5f} MB\".format((mem1 - mem0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Second Access\")\n",
    "mem0 = memory_usage_psutil()\n",
    "print(vol[-1].data)\n",
    "mem1 = memory_usage_psutil()\n",
    "print(\"Memory: {} - {}\".format(mem0, mem1))\n",
    "print(\"Memory added: {0:.5f} MB\".format((mem1 - mem0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Single Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol[-1].data.pipe(wrl.georef.georeference_dataset).DBZH[0].wradlib.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot same single sweep from Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol[-1].data.DBZH[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data\n",
    "\n",
    "Data can be exported to ODIMH5, CfRadial2 and NetCDF4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODIMH5\n",
    "\n",
    "ODIMH5 can only handle one volume not timeseries. So we have to select the timestep which we want to export.\n",
    "\n",
    "The example shows, how to output the volume to a ODIMH5-file, read it back and check for equality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol.to_odim(\"test_odim.h5\", timestep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol1 = wrl.io.open_odim(\"test_odim.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vol[0][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vol1[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.testing.assert_equal(vol[0][5].data, vol1[0][0].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CfRadial2\n",
    "\n",
    "CfRadial2 can only handle one volume not timeseries. So we have to select the timestep which we want to export.\n",
    "\n",
    "The example shows, how to output the volume to a CfRadial2-file and read it back. For there is currently no fitting counterpart to `open_odim` for reading CfRadial2 volumes we resort to `wradlib.io.CfRadial` reader and compare the underlying numpy arrays. As CfRadial2 data is sorted by time, we have to sort it by azimuth first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol.to_cfradial2(\"test_cfradial2.nc\", timestep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol2 = wrl.io.CfRadial(\"test_cfradial2.nc\", dim0=\"azimuth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_equal(\n",
    "    vol[0][5].data.DBZH.values, vol2[\"sweep_0\"].sortby(\"azimuth\").DBZH.values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NetCDF4\n",
    "\n",
    "Using this, the complete volume/timeseries is exported to a NetCDF4 file.\n",
    "\n",
    "The example shows, how to output the volume to such NetCDF4-file and read it back. For there is currently no fitting counterpart to `open_odim` for reading these NetCDF4 volumes we resort to `xarray.open_dataset` reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol.to_netcdf(\"test_netcdf.nc\", timestep=slice(None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol3 = xr.open_dataset(\"test_netcdf.nc\", group=\"sweep_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(vol3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.testing.assert_equal(vol[0][5].data, vol3.isel(time=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mom\n",
    "del swp\n",
    "del ts\n",
    "del vol\n",
    "del vol1\n",
    "del vol2\n",
    "del vol3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Garbage Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_end = memory_usage_psutil()\n",
    "print(\"Memory: {} - {}\".format(mem_start, mem_end))\n",
    "print(\"Memory still in use: {0:.5f} MB\".format((mem_end - mem_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Open files\n",
    "\n",
    "No open data files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_open_files(True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
